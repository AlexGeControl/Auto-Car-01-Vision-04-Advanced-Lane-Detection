{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "***\n",
    "\n",
    "## Project: **Advanced Lane Line Detection** \n",
    "***\n",
    "\n",
    "In this project, advanced lane line detection pipeline will be implemented and tested on static images and video streams.\n",
    "\n",
    "First, parameters of camera calibration should be estimated through the following steps:\n",
    "\n",
    "1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "2. Save the estimated parameters for deployment.\n",
    "\n",
    "The advanced lane line detection works as follows:\n",
    "1. Apply a distortion correction to raw images.\n",
    "2. Create a thresholded binary image using color transforms, gradients, etc.\n",
    "3. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "4. Detect lane pixels and fit to find the lane boundary.\n",
    "5. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "6. Warp the detected lane boundaries back onto the original image.\n",
    "7. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configuration file:\n",
    "from lane_line_detection.utils.conf import Conf\n",
    "# IO utilities:\n",
    "import random\n",
    "import glob\n",
    "from os.path import basename, splitext\n",
    "import json\n",
    "import pickle\n",
    "# Image processing:\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from lane_line_detection.rectifiers import DistortionRectifier\n",
    "from lane_line_detection.transformers import PerspectiveTransformer\n",
    "from lane_line_detection.binarizers import Binarizer\n",
    "from lane_line_detection.analyzers import Analyzer\n",
    "from lane_line_detection.analyzers import StreamAnalyzer\n",
    "from lane_line_detection.painters import Painter\n",
    "# Visualization:\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = Conf(\"conf/conf.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Distortion Rectifier\n",
    "\n",
    "***\n",
    "\n",
    "First, estimate camera distortion from chessboard images and build the rectifier for deployment. Two images would fail the chessboard detection test due to the poor imaging of the contained chessboard pattern.\n",
    "\n",
    "The attained rectifier will be dumped as pickle file for further access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build:\n",
    "rectifier = DistortionRectifier(\n",
    "    conf.calibration_images_descriptor\n",
    ")\n",
    "\n",
    "# Save for deployment:\n",
    "with open(conf.calibration_rectifier_pickle, \"wb\") as rectifier_pkl:\n",
    "    pickle.dump(rectifier, rectifier_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are one sample chessboard image and its rectified view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load rectifier:\n",
    "with open(conf.calibration_rectifier_pickle, \"rb\") as rectifier_pkl:\n",
    "    rectifier = pickle.load(rectifier_pkl)\n",
    "    \n",
    "# Rectify all test images:\n",
    "for test_image_filename in glob.glob(conf.test_images):\n",
    "    test_image = cv2.imread(\n",
    "        test_image_filename\n",
    "    )\n",
    "    filename, ext = splitext(basename(test_image_filename))\n",
    "    cv2.imwrite(\n",
    "        \"output_images/{}-rectified{}\".format(filename, ext),\n",
    "        rectifier.transform(test_image)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original & rectified:\n",
    "image_sample_original = mpimg.imread(\"camera_calibration/calibration1--9-by-5.jpg\")\n",
    "image_sample_rectified = rectifier.transform(\n",
    "    image_sample_original\n",
    ")\n",
    "\n",
    "# Initialize canvas:\n",
    "image_rectification_demo = plt.figure(figsize=(16, 9))\n",
    "\n",
    "# Original:\n",
    "ax=image_rectification_demo.add_subplot(1,2,1)\n",
    "plt.imshow(image_sample_original)\n",
    "ax.set_title(\"Chessboard--Original\")\n",
    "# Rectified:\n",
    "ax=image_rectification_demo.add_subplot(1,2,2)\n",
    "plt.imshow(image_sample_rectified)\n",
    "ax.set_title(\"Chessboard--Rectified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that after rectification, the glitches in the original chessboard image have been successfully removed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the Trapezoidal Zone for Pespective Transform\n",
    "\n",
    "***\n",
    "\n",
    "Next I would identify the trapezoidal zone needed for pespective transform.\n",
    "\n",
    "To select the appropriate four points for trapezoidal zone, I first annotated all the straight-line test images using [Sloth](https://github.com/cvhciKIT/sloth)\n",
    "\n",
    "The required points could be attained through statistical analysis of annotation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze annotation results:\n",
    "import json\n",
    "\n",
    "# Extract:\n",
    "with open(conf.perspective_transform_trapezoidal_annotation) as trapezoidal_annotation_file:    \n",
    "    trapezoidal_annotations = json.load(trapezoidal_annotation_file)\n",
    "\n",
    "# Transform\n",
    "X, Y = [], []\n",
    "for annotation in trapezoidal_annotations:\n",
    "    X.append(annotation[\"annotations\"][0][\"xn\"].split(';'))\n",
    "    Y.append(annotation[\"annotations\"][0][\"yn\"].split(';'))\n",
    "X = np.array(X, dtype=np.float)\n",
    "Y = np.array(Y, dtype=np.float)\n",
    "\n",
    "# Analyze:\n",
    "for name, point in zip(\n",
    "    (\"Top-Right\", \"Top-Left\", \"Bottom-Left\", \"Bottom-Right\"),\n",
    "    zip(\n",
    "        X.mean(axis=0), \n",
    "        Y.mean(axis=0)\n",
    "    )\n",
    "):\n",
    "    x_relative, y_relative = point\n",
    "    print(\n",
    "        \"[{:>12}]: ({:.1f}, {:.1f})\".format(\n",
    "            name, x_relative, y_relative\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above analysis, my final four-point perspective transformation pairs are as follows:\n",
    "\n",
    "```json\n",
    "\t\"perspective_transform_source\": [\n",
    "\t\t[ 689.1, 452.1],\n",
    "\t\t[ 594.2, 452.1],\n",
    "\t\t[ 246.5, 696.8],\n",
    "\t\t[1069.7, 696.8]\n",
    "\t],\n",
    "\t\"perspective_transform_destination\": [\n",
    "        [   960,     1],\n",
    "        [   320,     1],\n",
    "        [   320,   718],\n",
    "        [   960,   718]\n",
    "\t]\n",
    "```\n",
    "\n",
    "The above parameters have all been saved in the json configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build:\n",
    "transformer = PerspectiveTransformer(\n",
    "    conf.perspective_transform_source,\n",
    "    conf.perspective_transform_destination,\n",
    "    tuple(conf.frame_size)\n",
    ")\n",
    "\n",
    "# Save for deployment:\n",
    "with open(conf.perspective_transformer_pickle, \"wb\") as transformer_pkl:\n",
    "    pickle.dump(transformer, transformer_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build painter:\n",
    "painter = Painter(transformer)\n",
    "\n",
    "# Save for deployment:\n",
    "with open(conf.painter_pickle, \"wb\") as painter_pkl:\n",
    "    pickle.dump(painter, painter_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load transformer:\n",
    "with open(conf.perspective_transformer_pickle, \"rb\") as transformer_pkl:\n",
    "    transformer = pickle.load(transformer_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load transformer:\n",
    "with open(conf.painter_pickle, \"rb\") as painter_pkl:\n",
    "    painter = pickle.load(painter_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original & rectified:\n",
    "image_sample_original = mpimg.imread(\"test_images/straight-lines01.jpg\")\n",
    "image_sample_rectified = rectifier.transform(\n",
    "    image_sample_original\n",
    ")\n",
    "image_sample_transformed = transformer.transform(\n",
    "    image_sample_rectified\n",
    ")\n",
    "\n",
    "# Initialize canvas:\n",
    "perspective_transformation_demo = plt.figure(figsize=(16, 9))\n",
    "\n",
    "# Original:\n",
    "ax=perspective_transformation_demo.add_subplot(1,2,1)\n",
    "plt.imshow(\n",
    "    cv2.polylines(\n",
    "        image_sample_rectified, \n",
    "        [\n",
    "            np.array(\n",
    "                conf.perspective_transform_source,\n",
    "                dtype=np.int\n",
    "            )\n",
    "        ], \n",
    "        True,\n",
    "        (0, 255, 0),\n",
    "        6\n",
    "    )\n",
    ")\n",
    "ax.set_title(\"Straight Lane Lines--Rectified\")\n",
    "# Rectified:\n",
    "ax=perspective_transformation_demo.add_subplot(1,2,2)\n",
    "plt.imshow(\n",
    "    cv2.polylines(\n",
    "        image_sample_transformed, \n",
    "        [\n",
    "            np.array(\n",
    "                conf.perspective_transform_destination,\n",
    "                dtype=np.int\n",
    "            )\n",
    "        ], \n",
    "        True,\n",
    "        (0, 255, 0),\n",
    "        6\n",
    "    )\n",
    ")\n",
    "ax.set_title(\"Straight Lane Lines--Transformed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Binarizer\n",
    "\n",
    "***\n",
    "\n",
    "Here I threshold the image based on:\n",
    "\n",
    "1. The magnitude of grad_x;\n",
    "2. The value of saturation;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build:\n",
    "binarizer = Binarizer(\n",
    "    conf.frame_size,\n",
    "    conf.binarizer_ROI,\n",
    "    conf.binarizer_yellow_lane_hue_thresholds,\n",
    "    conf.binarizer_yellow_lane_saturation_thresholds,\n",
    "    conf.binarizer_white_lane_saturation_thresholds,\n",
    "    conf.binarizer_white_lane_value_thresholds,\n",
    "    conf.binarizer_gradient_kernel_size,\n",
    "    conf.binarizer_gradient_thresholds,\n",
    "    conf.binarizer_morphology_kernel_size\n",
    ")\n",
    "\n",
    "# Save for deployment:\n",
    "with open(conf.binarizer_pickle, \"wb\") as binarizer_pkl:\n",
    "    pickle.dump(binarizer, binarizer_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load binarizer:\n",
    "with open(conf.binarizer_pickle, \"rb\") as binarizer_pkl:\n",
    "    binarizer = pickle.load(binarizer_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_filename in sorted(glob.glob(conf.test_images)):\n",
    "    # Binarized & transformed:\n",
    "    image_sample_original = cv2.imread(\n",
    "        image_filename\n",
    "    )\n",
    "    image_sample_thresholded = binarizer.transform(\n",
    "        image_sample_original\n",
    "    )\n",
    "    image_sample_rectified = rectifier.transform(\n",
    "        image_sample_thresholded\n",
    "    )\n",
    "    image_sample_transformed = transformer.transform(\n",
    "        image_sample_rectified\n",
    "    )\n",
    "\n",
    "    # Initialize canvas:\n",
    "    thresholding_demo = plt.figure(figsize=(16, 9))\n",
    "\n",
    "    # Original:\n",
    "    ax=thresholding_demo.add_subplot(1,2,1)\n",
    "    plt.imshow(\n",
    "        cv2.cvtColor(image_sample_original, cv2.COLOR_BGR2RGB)\n",
    "    )\n",
    "    ax.set_title(\"{} Original\".format(basename(image_filename)))\n",
    "    # Rectified:\n",
    "    ax=thresholding_demo.add_subplot(1,2,2)\n",
    "    plt.imshow(\n",
    "        image_sample_transformed, cmap=\"gray\"\n",
    "    )\n",
    "    ax.set_title(\"{} Transformed\".format(basename(image_filename)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Lane Analyzer\n",
    "\n",
    "***\n",
    "\n",
    "Here I choose to implement linear SVM using LinearSVC because the dimensions of training dataset,(35520, -1), is formidable. Use SVC will lead to a very slow training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build:\n",
    "analyzer = Analyzer(\n",
    "    conf.analyzer_window_size,\n",
    "    conf.analyzer_offset,\n",
    "    conf.analyzer_meter_per_pix\n",
    ")\n",
    "\n",
    "# Save for deployment:\n",
    "with open(conf.analyzer_pickle, \"wb\") as analyzer_pkl:\n",
    "    pickle.dump(analyzer, analyzer_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load analyzer:\n",
    "with open(conf.analyzer_pickle, \"rb\") as analyzer_pkl:\n",
    "    analyzer = pickle.load(analyzer_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Static Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image_sample_original):\n",
    "    # Step 1--Rectify\n",
    "    image_sample_rectified = rectifier.transform(\n",
    "        image_sample_original\n",
    "    )\n",
    "    # Step 2--Threshold\n",
    "    image_sample_thresholded = binarizer.transform(\n",
    "        image_sample_rectified\n",
    "    )\n",
    "    # Step 3--Warp:\n",
    "    image_sample_transformed = transformer.transform(\n",
    "        image_sample_thresholded\n",
    "    )\n",
    "\n",
    "    # Step 4--Get lane line params:\n",
    "    params = analyzer.transform(image_sample_transformed)\n",
    "    \n",
    "    # Step 5--Inpainting\n",
    "    if params is None:\n",
    "        image_sample_processed = image_sample_rectified\n",
    "    else:\n",
    "        (lane_line_params, curverads, offset) = params\n",
    "        image_sample_processed = painter.transform(\n",
    "            image_sample_rectified,\n",
    "            lane_line_params,\n",
    "            curverads,\n",
    "            offset\n",
    "        )\n",
    "    \n",
    "    return image_sample_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_filename in sorted(glob.glob(conf.test_images)):\n",
    "    image_sample_original = cv2.imread(image_filename)\n",
    "    image_sample_processed = process_image(image_sample_original)\n",
    "    \n",
    "    # Initialize canvas:\n",
    "    lane_analysis_demo = plt.figure(figsize=(16, 9))\n",
    "\n",
    "    # Original:\n",
    "    ax=lane_analysis_demo.add_subplot(1,2,1)\n",
    "    plt.imshow(\n",
    "        cv2.cvtColor(\n",
    "            image_sample_original,\n",
    "            cv2.COLOR_BGR2RGB\n",
    "        )\n",
    "    )\n",
    "    ax.set_title(\"{} Original\".format(basename(image_filename)))\n",
    "    # Rectified:\n",
    "    ax=lane_analysis_demo.add_subplot(1,2,2)\n",
    "    plt.imshow(\n",
    "        cv2.cvtColor(\n",
    "            image_sample_processed,\n",
    "            cv2.COLOR_BGR2RGB\n",
    "        )\n",
    "    )\n",
    "    ax.set_title(\"{} Analyzed\".format(basename(image_filename)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from multiprocessing import Pool\n",
    "from moviepy.editor import concatenate_videoclips\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build:\n",
    "stream_analyzer = StreamAnalyzer(\n",
    "    conf.analyzer_window_size,\n",
    "    conf.analyzer_offset,\n",
    "    conf.analyzer_meter_per_pix,\n",
    "    conf.stream_analyzer_temporal_filter_len\n",
    ")\n",
    "\n",
    "# Save for deployment:\n",
    "with open(conf.stream_analyzer_pickle, \"wb\") as stream_analyzer_pkl:\n",
    "    pickle.dump(stream_analyzer, stream_analyzer_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load analyzer:\n",
    "with open(conf.stream_analyzer_pickle, \"rb\") as stream_analyzer_pkl:\n",
    "    stream_analyzer = pickle.load(stream_analyzer_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_frame(frame):    \n",
    "    # Step 0--Format:\n",
    "    original = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Step 1--Rectify\n",
    "    rectified = rectifier.transform(\n",
    "        original\n",
    "    )\n",
    "    # Step 2--Threshold\n",
    "    thresholded = binarizer.transform(\n",
    "        rectified\n",
    "    )\n",
    "    # Step 3--Warp:\n",
    "    transformed = transformer.transform(\n",
    "        thresholded\n",
    "    )\n",
    "\n",
    "    # Step 4--Get lane line params:\n",
    "    params = stream_analyzer.transform(transformed)\n",
    "    \n",
    "    # Step 5--Inpainting\n",
    "    (lane_line_params, curverads, offset) = params\n",
    "    processed = painter.transform(\n",
    "        rectified,\n",
    "        lane_line_params,\n",
    "        curverads,\n",
    "        offset\n",
    "    )\n",
    "    \n",
    "    return cv2.cvtColor(processed, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IO config:\n",
    "video_project_input = \"test_videos/project_video.mp4\"\n",
    "video_project_output = \"output_videos/project_video_detected.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Process:\n",
    "clip_project = VideoFileClip(video_project_input)\n",
    "clip_project_detected = clip_project.fl_image(process_frame)\n",
    "%time clip_project_detected.write_videofile(video_project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display:\n",
    "HTML(\n",
    "    \"\"\"\n",
    "    <video width=\"960\" height=\"540\" controls>\n",
    "      <source src=\"{0}\">\n",
    "    </video>\n",
    "    \"\"\".format(video_project_output)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IO config:\n",
    "video_challenge_input = \"test_videos/challenge_video.mp4\"\n",
    "video_challenge_output = \"output_videos/challenge_video_detected.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process:\n",
    "clip_challenge = VideoFileClip(video_challenge_input)\n",
    "clip_challenge_detected = clip_challenge.fl_image(process_frame)\n",
    "%time clip_challenge_detected.write_videofile(video_challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display:\n",
    "HTML(\n",
    "    \"\"\"\n",
    "    <video width=\"960\" height=\"540\" controls>\n",
    "      <source src=\"{0}\">\n",
    "    </video>\n",
    "    \"\"\".format(video_challenge_output)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
